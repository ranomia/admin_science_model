# 行政事業レビューデータを用いた科学技術事業分類モデル構築計画書

## 1. プロジェクト概要

### 1.1 目的
行政事業レビューデータを用いて、政府事業が科学技術関連事業であるかを自動分類するモデルを構築する。

### 1.2 対象データ
- **訓練データ**: `data/raw/train_deduplicated.csv` (13,078件)
- **評価データ**: `data/raw/test_deduplicated.csv` (2,350件)
- **目的変数**: `science_tech_decision` (該当/非該当の2値分類)
- **除外特徴量**: `science_tech_category` (利用禁止)

### 1.3 期待される成果
- 高精度な科学技術事業分類モデルの構築
- 行政事業レビューの効率化への貢献
- ModernBERTの日本語行政文書への適用可能性の検証

## 2. データ分析

### 2.1 データ構造
以下の特徴量が利用可能：
- `project_id`: プロジェクトID
- `project_fiscal_year`: 事業年度
- `project_name`: 事業名
- `responsible_ministry`: 所管省庁
- `project_objective`: 事業目的
- `current_issues`: 現在の課題
- `project_summary`: 事業概要
- `project_start_year`: 事業開始年
- `project_end_year`: 事業終了年
- `initial_budget`: 当初予算
- `supplementary_budget`: 補正予算

### 2.2 テキスト特徴量の活用
主要なテキスト情報を結合して分類に使用：
- 事業名 + 事業目的 + 事業概要 + 現在の課題
- 所管省庁情報も補助的に活用

### 2.3 データ前処理
- 欠損値の処理（空文字列やNaNの統一的処理）
- テキストの正規化（改行文字、特殊文字の処理）
- 長すぎるテキストの適切な切り詰め（ModernBERTの最大長8,192トークンを考慮）

## 3. モデル選択と根拠

### 3.1 ModernBERTの選択理由
1. **最新のアーキテクチャ**: RoPE、GeGLU、Flash Attentionなどの最新技術を統合
2. **長文処理能力**: 8,192トークンの長いコンテキストに対応
3. **日本語性能**: SBIntuitionsのModernBERT-jaは日本語テキストに最適化
4. **効率性**: 従来のBERTと比較して高速な訓練・推論が可能
5. **実証された性能**: 日本語の医療・行政文書での高い性能が報告されている

### 3.2 候補モデル
- **主力モデル**: `sbintuitions/modernbert-ja-130m`
- **比較対象**: `tohoku-nlp/bert-base-japanese-v3`（ベースライン）

## 4. 実験設計

### 4.1 実験フェーズ
1. **Phase 1**: データ探索・前処理・ベースライン構築
2. **Phase 2**: ModernBERTファインチューニング・ハイパーパラメータ調整
3. **Phase 3**: モデル評価・比較分析・結果解釈

### 4.2 評価指標
- **主要指標**: F1スコア（バランスの取れた評価）
- **補助指標**: 
  - Precision（精密度）
  - Recall（再現率）
  - Accuracy（正解率）
  - AUC-ROC（ROC曲線下面積）

### 4.3 クロスバリデーション
- 5-fold Cross Validationによる安定性評価
- 層化サンプリングによるクラス比率の維持

## 5. 技術仕様

### 5.1 開発環境
- **フレームワーク**: PyTorch + Transformers
- **GPU**: NVIDIA GPU（VRAM 16GB以上推奨）
- **Python**: 3.8以上
- **主要ライブラリ**: transformers, torch, scikit-learn, pandas, numpy

### 5.2 ハイパーパラメータ
**初期設定**（調整対象）：
- Learning Rate: 2e-5, 3e-5, 5e-5
- Batch Size: 8, 16, 32
- Epochs: 3, 4, 5
- Max Length: 512, 1024, 2048
- Warmup Steps: 10% of total steps
- Weight Decay: 0.01

### 5.3 最適化戦略
- **オプティマイザー**: AdamW
- **スケジューラー**: Linear warmup + cosine decay
- **正則化**: Dropout (0.1), Weight decay
- **Early Stopping**: validation F1スコアでの監視

## 6. 実装計画

### 6.1 ディレクトリ構造
```
src/
├── data/
│   ├── preprocessing.py
│   └── dataset.py
├── models/
│   ├── modernbert_classifier.py
│   └── baseline_models.py
├── training/
│   ├── trainer.py
│   └── utils.py
├── evaluation/
│   ├── metrics.py
│   └── analysis.py
└── config/
    └── config.yaml
```

### 6.2 開発スケジュール
- **Week 1**: データ前処理・EDA・ベースライン構築
- **Week 2**: ModernBERTモデル実装・初期実験
- **Week 3**: ハイパーパラメータ調整・モデル最適化
- **Week 4**: 最終評価・結果分析・レポート作成

## 7. リスク分析と対策

### 7.1 技術的リスク
- **メモリ不足**: バッチサイズ調整、勾配蓄積の活用
- **過学習**: 正則化強化、Early Stopping
- **クラス不均衡**: 重み付き損失関数、SMOTE等の適用検討

### 7.2 データ品質リスク
- **ノイズデータ**: データクリーニングの徹底
- **ラベル品質**: 専門家によるサンプル検証
- **ドメインシフト**: ドメイン適応手法の検討

## 8. 期待される成果物

### 8.1 モデル成果物
- 学習済みModernBERTモデル
- 推論用パイプライン
- モデル性能レポート

### 8.2 分析レポート
- データ分析結果
- モデル比較分析
- 特徴量重要度分析
- エラー分析・改善提案

### 8.3 技術文書
- モデル仕様書
- API仕様書
- 運用ガイドライン

## 9. 成功基準

### 9.1 性能目標
- **主目標**: F1スコア 0.85以上
- **副目標**: ベースラインBERTモデルからの+5%以上の改善

### 9.2 効率性目標
- 推論時間: 1文書あたり100ms以下
- メモリ使用量: 8GB GPU環境での動作

## 10. 今後の展開

### 10.1 モデル改善
- アンサンブル手法の適用
- マルチタスク学習の検討
- ドメイン特化型事前学習

### 10.2 実用化に向けて
- Web APIとしての提供
- バッチ処理システムの構築
- 継続学習機能の実装

---

**作成日**: 2025年1月
**作成者**: AI開発チーム
**承認者**: プロジェクトマネージャー

## 11. 開発チェックリスト

### 11.1 Phase 1: データ探索・前処理・ベースライン構築

#### データ探索・分析
- [ ] 訓練データ（train_deduplicated.csv）の読み込み確認
- [ ] テストデータ（test_deduplicated.csv）の読み込み確認
- [ ] データ形状・構造の確認（行数、列数、データ型）
- [ ] 目的変数（science_tech_decision）の分布確認
- [ ] 欠損値の分析（各列の欠損率）
- [ ] テキスト特徴量の長さ分布分析
- [ ] クラス不均衡の確認と対策検討
- [ ] 所管省庁別の分布確認
- [ ] 事業年度別の分布確認

#### データ前処理
- [ ] 欠損値処理の実装（NaN、空文字列の統一処理）
- [ ] テキスト正規化の実装（改行、特殊文字処理）
- [ ] テキスト結合処理の実装（事業名+目的+概要+課題）
- [ ] トークン長制限の実装（ModernBERT用）
- [ ] データセット分割の実装（train/validation）
- [ ] 前処理パイプラインのテスト
- [ ] 前処理済みデータの保存

#### ベースラインモデル構築
- [ ] scikit-learn環境のセットアップ
- [ ] TF-IDF特徴量抽出の実装
- [ ] ロジスティック回帰モデルの構築
- [ ] ランダムフォレストモデルの構築
- [ ] ベースライン性能の評価
- [ ] 評価指標の計算・可視化

### 11.2 Phase 2: ModernBERTファインチューニング・ハイパーパラメータ調整

#### 環境構築
- [ ] PyTorch環境のセットアップ
- [ ] Transformersライブラリのインストール
- [ ] GPU環境の確認・設定
- [ ] ModernBERTモデルのダウンロード・確認
- [ ] 必要なライブラリの依存関係確認

#### モデル実装
- [ ] ModernBERTTokenizerの実装
- [ ] カスタムDatasetクラスの実装
- [ ] DataLoaderの実装
- [ ] ModernBERT分類器の実装
- [ ] 損失関数の実装（重み付き対応）
- [ ] 評価指標の実装

#### 訓練パイプライン
- [ ] 訓練ループの実装
- [ ] バリデーションループの実装
- [ ] Early Stoppingの実装
- [ ] モデル保存・読み込み機能
- [ ] ログ出力機能の実装
- [ ] 学習曲線の可視化機能

#### 初期実験
- [ ] 小規模データでの動作確認
- [ ] 初期ハイパーパラメータでの訓練実行
- [ ] 訓練時間・メモリ使用量の確認
- [ ] 初期結果の評価・分析
- [ ] 問題点の特定・修正

#### ハイパーパラメータ調整
- [ ] Learning Rate探索（2e-5, 3e-5, 5e-5）
- [ ] Batch Size調整（8, 16, 32）
- [ ] Epochs数調整（3, 4, 5）
- [ ] Max Length調整（512, 1024, 2048）
- [ ] 各設定での性能評価
- [ ] 最適パラメータの決定

### 11.3 Phase 3: モデル評価・比較分析・結果解釈

#### クロスバリデーション
- [ ] 5-fold CV実装
- [ ] 層化サンプリングの実装
- [ ] CV結果の集計・分析
- [ ] 安定性評価の実施
- [ ] 統計的有意性検定

#### モデル比較
- [ ] ModernBERT vs ベースラインの比較
- [ ] 各評価指標での詳細比較
- [ ] 統計的有意差の検定
- [ ] 実行時間・メモリ使用量の比較
- [ ] コストパフォーマンス分析

#### 詳細分析
- [ ] 混同行列の作成・分析
- [ ] クラス別性能分析
- [ ] エラー分析の実施
- [ ] 特徴量重要度分析（SHAP/LIME）
- [ ] 所管省庁別性能分析
- [ ] 事業年度別性能分析

#### 結果解釈・可視化
- [ ] ROC曲線・PR曲線の作成
- [ ] 学習曲線の分析
- [ ] 予測確信度分布の分析
- [ ] 誤分類事例の詳細分析
- [ ] ビジネス影響度の評価

### 11.4 最終化・文書化

#### モデル最終化
- [ ] 最終モデルの訓練
- [ ] モデル性能の最終確認
- [ ] 推論パイプラインの実装
- [ ] バッチ推論機能の実装
- [ ] モデルの保存・バージョン管理

#### テスト・検証
- [ ] 単体テストの作成・実行
- [ ] 統合テストの実行
- [ ] 性能テストの実行
- [ ] エッジケースの検証
- [ ] 本番環境での動作確認

#### 文書化
- [ ] モデル仕様書の作成
- [ ] API仕様書の作成
- [ ] 運用ガイドラインの作成
- [ ] 技術レポートの作成
- [ ] プレゼンテーション資料の作成

#### 成果物確認
- [ ] 学習済みモデルファイル
- [ ] 推論用コード
- [ ] 評価結果レポート
- [ ] 技術文書一式
- [ ] デモンストレーション準備

### 11.5 品質保証チェック

#### コード品質
- [ ] コードレビューの実施
- [ ] PEP8準拠の確認
- [ ] 型ヒントの追加
- [ ] docstringの完備
- [ ] リファクタリングの実施

#### 再現性確保
- [ ] 乱数シードの固定
- [ ] 環境設定の文書化
- [ ] requirements.txtの作成
- [ ] 実行手順書の作成
- [ ] 結果再現の確認

#### セキュリティ・コンプライアンス
- [ ] データ取扱い規則の遵守確認
- [ ] 個人情報保護対策の確認
- [ ] セキュリティ脆弱性の確認
- [ ] ライセンス確認
- [ ] 法的要件の確認

---

**更新日**: 2025年1月
**作成者**: AI開発チーム
**承認者**: プロジェクトマネージャー 